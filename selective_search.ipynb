{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import cv2\n",
    "import numpy \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "import pickle\n",
    "import os\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class selective_tracker():\n",
    "\n",
    "    data = pandas.read_csv('/Users/akshitshishodia/intern/tracker/annotation/labels_my-project-name_2023-07-09-02-49-05.csv')\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def calculate_iou(box_a,box_b):\n",
    "        xA = max(box_a[0],box_b[0])\n",
    "        yA = max(box_a[1],box_b[1])\n",
    "        xB = min(box_a[2],box_b[2])\n",
    "        yB = min(box_a[3],box_b[3])\n",
    "        inter_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "        pred = (box_a[2]-box_a[0]+1)*(box_a[3]-box_a[1]+1)\n",
    "        ground_truth = (box_b[2]-box_b[0]+1)*(box_b[3]-box_b[1]+1)\n",
    "        iou = inter_area / float(pred + ground_truth - inter_area)\n",
    "        return iou\n",
    "    \n",
    "    @classmethod\n",
    "    def annotation_extracter(cls,path):\n",
    "        totalpos = 0\n",
    "        totalneg = 0\n",
    "        image_path = [file for file in os.listdir(path=path)]\n",
    "        for image_loc in image_path:\n",
    "            try:\n",
    "                row = cls.data[cls.data['image_name']== image_loc]\n",
    "                \n",
    "\n",
    "                w = int(row.image_width)\n",
    "                h = int(row.image_height)\n",
    "                x_min = int(row.bbox_x)\n",
    "                y_min = int(row.bbox_y)\n",
    "                x_max= int(row.bbox_x)+int(row.bbox_width)\n",
    "                y_max = int(row.bbox_y)+int(row.bbox_height)\n",
    "\n",
    "                x_min = max(0,x_min)\n",
    "                y_min = max(0,y_min)\n",
    "                x_max = min(w,x_max)\n",
    "                y_max = min(h,y_max)\n",
    "\n",
    "                gt_box = (x_min,y_min,x_max,y_max)\n",
    "            except:\n",
    "                continue\n",
    "            img = cv2.imread(os.path.join(path,image_loc))\n",
    "            ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "            ss.setBaseImage(img)\n",
    "            ss.switchToSelectiveSearchQuality()\n",
    "            rects = ss.process()\n",
    "            proposedRegions = list()\n",
    "            for x,y,w,h in rects:\n",
    "                proposedRegions.append((x,y,x+w,y+h))\n",
    "\n",
    "            pos_roi = 0\n",
    "            neg_roi = 0\n",
    "\n",
    "            for proposedRect in proposedRegions[:2000]:\n",
    "                (x1,y1,x2,y2) = proposedRect\n",
    "\n",
    "                IOU = cls.calculate_iou(gt_box,proposedRect)\n",
    "                roi = None\n",
    "                OutputPath = None\n",
    "                (gx1,gy1,gx2,gy2) = gt_box\n",
    "\n",
    "                if IOU > 0.7 and pos_roi <= 30:\n",
    "                    roi = img[y1:y2,x1:x2]\n",
    "                    loc = str(totalpos)+'.png'\n",
    "                    OutputPath = os.path.join('/Users/akshitshishodia/intern/tracker/refined/gripper',loc)\n",
    "                    totalpos+=1\n",
    "                    pos_roi+=1                            \n",
    "                fullOverlap = x1 >= gx1\n",
    "                fullOverlap = fullOverlap and y1 >= gy1\n",
    "                fullOverlap = fullOverlap and x2 <= gx2\n",
    "                fullOverlap = fullOverlap and y2 <= gy2\n",
    "\n",
    "                if not fullOverlap and IOU < 0.1 and neg_roi <= 10:\n",
    "                    roi = img[y1:y2,x1:x2]\n",
    "                    loc = str(totalneg)+'.png'\n",
    "                    OutputPath = os.path.join('/Users/akshitshishodia/intern/tracker/refined/not gripper',loc)\n",
    "                    totalneg+=1\n",
    "                    neg_roi+=1\n",
    "                \n",
    "                if roi is not None and OutputPath is not None:\n",
    "                    roi = cv2.resize(roi,(224,224),cv2.INTER_CUBIC)\n",
    "                    cv2.imwrite(OutputPath,roi)\n",
    "\n",
    "    def build_model(self):\n",
    "        EPOCHS = 5\n",
    "        BS = 32\n",
    "        LR = 1e-4\n",
    "        data = list()\n",
    "        labels = list()\n",
    "        #gripper\n",
    "        im_path = paths.list_images('/Users/akshitshishodia/intern/tracker/refined')\n",
    "\n",
    "        for im in im_path:\n",
    "            label = im.split(os.path.sep)[-2]\n",
    "            image = load_img(im,target_size=(224,224))\n",
    "            image = img_to_array(image)\n",
    "            image = preprocess_input(image)\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "        data = numpy.array(data,dtype='float32')\n",
    "        labels = numpy.array(labels)\n",
    "\n",
    "\n",
    "        lb = LabelBinarizer()\n",
    "        labels = lb.fit_transform(labels)\n",
    "        labels = to_categorical(labels)\n",
    "\n",
    "        (trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\n",
    "        augment = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            zoom_range=0.15,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.15,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "\n",
    "        base_model = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "        headModel = base_model.output\n",
    "        headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "        headModel = Flatten(name=\"flatten\")(headModel)\n",
    "        headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "        headModel = Dropout(0.5)(headModel)\n",
    "        headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=headModel)\n",
    "\n",
    "        # for layer in base_model.layers():\n",
    "        #     layer.trainable = False\n",
    "        \n",
    "        opt =  Adam(LR)\n",
    "        model.compile(loss = 'binary_crossentropy',optimizer = opt,metrics = ['accuracy'])\n",
    "        History = model.fit(\n",
    "        augment.flow(trainX, trainY, batch_size=BS),\n",
    "        steps_per_epoch=len(trainX) // BS,\n",
    "        validation_data=(testX, testY),\n",
    "        validation_steps=len(testX) // BS,\n",
    "        epochs=EPOCHS)\n",
    "\n",
    "\n",
    "        model.save('model_3.h5',save_format = 'h5')\n",
    "        f = open('label_encoder.pickle', \"wb\")\n",
    "        f.write(pickle.dumps(lb))\n",
    "        f.close()\n",
    "        return History,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.4094 - accuracy: 0.8784 - val_loss: 0.2149 - val_accuracy: 0.9802\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.0991 - accuracy: 0.9865 - val_loss: 0.1657 - val_accuracy: 0.9802\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9802\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9901\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "tracker = selective_tracker()\n",
    "\n",
    "history,_ = tracker.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "import imutils\n",
    "model = tensorflow.keras.models.load_model('/Users/akshitshishodia/intern/tracker/model_3.h5')\n",
    "lb = pickle.loads(open('/Users/akshitshishodia/intern/tracker/label_encoder.pickle','rb').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 193ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \tcv2\u001b[39m.\u001b[39mputText(clone, text, (startX, y),\n\u001b[1;32m     37\u001b[0m \t\tcv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m0.45\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m     38\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mBefore NMS\u001b[39m\u001b[39m\"\u001b[39m, clone)\n\u001b[0;32m---> 39\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "test_image = cv2.imread('/Users/akshitshishodia/intern/tracker/DATASET_/frame220.png')\n",
    "\n",
    "test_image = imutils.resize(test_image,width=500)\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(test_image)\n",
    "ss.switchToSelectiveSearchQuality()\n",
    "rects = ss.process()\n",
    "proposals = list()\n",
    "box= list()\n",
    "for x,y,w,h in rects[:200]:\n",
    "    roi = test_image[y:y+h,x:x+w]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "    roi = img_to_array(roi)\n",
    "    roi = preprocess_input(roi)\n",
    "    proposals.append(roi)\n",
    "    box.append((x,y,x+w,y+h))\n",
    "proposals = numpy.array(proposals,dtype = numpy.int32)\n",
    "box = numpy.array(box,dtype = numpy.int32)\n",
    "\n",
    "proba = model.predict(proposals)\n",
    "labels = lb.classes_[numpy.argmax(proba,axis =1 )]\n",
    "index = numpy.where(labels == 'gripper')[0]\n",
    "box = box[index]\n",
    "proba = proba[index][:,1]\n",
    "index = numpy.where(proba >= 0.90)\n",
    "box = box[index]\n",
    "proba = proba[index]\n",
    "clone = test_image.copy()\n",
    "for (box, prob) in zip(box, proba):\n",
    "\t(startX, startY, endX, endY) = box\n",
    "\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "\t\t(0, 255, 0), 2)\n",
    "\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\ttext= \"gripper: {:.2f}%\".format(prob * 100)\n",
    "\tcv2.putText(clone, text, (startX, y),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Before NMS\", clone)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

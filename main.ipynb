{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>bbox_x</th>\n",
       "      <th>bbox_y</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gripper</td>\n",
       "      <td>772</td>\n",
       "      <td>518</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>0.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gripper</td>\n",
       "      <td>678</td>\n",
       "      <td>502</td>\n",
       "      <td>126</td>\n",
       "      <td>147</td>\n",
       "      <td>10.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gripper</td>\n",
       "      <td>776</td>\n",
       "      <td>527</td>\n",
       "      <td>107</td>\n",
       "      <td>123</td>\n",
       "      <td>100.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gripper</td>\n",
       "      <td>776</td>\n",
       "      <td>527</td>\n",
       "      <td>111</td>\n",
       "      <td>124</td>\n",
       "      <td>102.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gripper</td>\n",
       "      <td>770</td>\n",
       "      <td>520</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>104.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>gripper</td>\n",
       "      <td>663</td>\n",
       "      <td>510</td>\n",
       "      <td>107</td>\n",
       "      <td>142</td>\n",
       "      <td>90.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>gripper</td>\n",
       "      <td>682</td>\n",
       "      <td>510</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>92.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>gripper</td>\n",
       "      <td>743</td>\n",
       "      <td>526</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>94.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>gripper</td>\n",
       "      <td>774</td>\n",
       "      <td>518</td>\n",
       "      <td>117</td>\n",
       "      <td>128</td>\n",
       "      <td>96.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>gripper</td>\n",
       "      <td>772</td>\n",
       "      <td>520</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>98.png</td>\n",
       "      <td>1440</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_name  bbox_x  bbox_y  bbox_width  bbox_height image_name  \\\n",
       "0      gripper     772     518         123          128      0.png   \n",
       "1      gripper     678     502         126          147     10.png   \n",
       "2      gripper     776     527         107          123    100.png   \n",
       "3      gripper     776     527         111          124    102.png   \n",
       "4      gripper     770     520         115          128    104.png   \n",
       "..         ...     ...     ...         ...          ...        ...   \n",
       "200    gripper     663     510         107          142     90.png   \n",
       "201    gripper     682     510         123          128     92.png   \n",
       "202    gripper     743     526         121          121     94.png   \n",
       "203    gripper     774     518         117          128     96.png   \n",
       "204    gripper     772     520         115          128     98.png   \n",
       "\n",
       "     image_width  image_height  \n",
       "0           1440           900  \n",
       "1           1440           900  \n",
       "2           1440           900  \n",
       "3           1440           900  \n",
       "4           1440           900  \n",
       "..           ...           ...  \n",
       "200         1440           900  \n",
       "201         1440           900  \n",
       "202         1440           900  \n",
       "203         1440           900  \n",
       "204         1440           900  \n",
       "\n",
       "[205 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"/Users/akshitshishodia/tracker/labels from robodk.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "    \n",
    "    H = 512\n",
    "    W = 512\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_model(input_shape):\n",
    "        input = layers.Input(input_shape)\n",
    "\n",
    "        pre_trained = MobileNetV2(\n",
    "            include_top = False,\n",
    "            weights = \"imagenet\",\n",
    "            input_tensor = input,\n",
    "            alpha = 1.0\n",
    "        )\n",
    "        pre_trained.trainable = False\n",
    "        x = pre_trained.output\n",
    "        x = layers.Conv2D(256, kernel_size=1, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(4, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(input,x)\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def load_dataset(split = 0.2):\n",
    "        data = pandas.read_csv('/Users/akshitshishodia/tracker/labels from robodk.csv')\n",
    "        path  = '/Users/akshitshishodia/tracker/DATASET_/DATASET_/'\n",
    "        image = list()\n",
    "        bounding_box = list()\n",
    "\n",
    "        for idx,rows in data.iterrows():\n",
    "            name = path + str(rows['image_name'])\n",
    "            bbox = [rows['bbox_x'],rows['bbox_y'],rows['bbox_width'],rows['bbox_height']]\n",
    "            image.append(name)\n",
    "            bounding_box.append(bbox)\n",
    "        \n",
    "        sample_size = int(len(image)*0.2)\n",
    "        \n",
    "        train_x, valid_x = train_test_split(image,test_size=sample_size,random_state=42)\n",
    "        train_y, valid_y = train_test_split(bounding_box,test_size=sample_size,random_state=42)\n",
    "\n",
    "        train_x, test_x = train_test_split(train_x,test_size=sample_size,random_state=42)\n",
    "        train_y, test_y = train_test_split(train_y, test_size=sample_size, random_state=42)\n",
    "\n",
    "        return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "    @classmethod\n",
    "    def read_image(cls,path,bbox):\n",
    "        path = path.decode()\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        height,width,_ = img.shape\n",
    "        img = cv2.resize(img,(cls.W,cls.H))\n",
    "        img = (img-127.5)/127.5\n",
    "        img = img.astype(numpy.float32)\n",
    "\n",
    "        x,y,w,h = bbox\n",
    "        x_c = x+w\n",
    "        y_c = y+h\n",
    "\n",
    "        norm_x = float(x/width)\n",
    "        norm_y = float(y/height)\n",
    "        norm_xc = float(x_c/width)\n",
    "        norm_yc = float(y_c/height)\n",
    "        \n",
    "        normalised = numpy.array([norm_x,norm_y,norm_xc,norm_yc],dtype = numpy.float32)\n",
    "\n",
    "        return img, normalised\n",
    "    \n",
    "    @classmethod \n",
    "    def parse(cls,x,y):\n",
    "        x,y = tensorflow.numpy_function(cls.read_image,[x,y],[tensorflow.float32,tensorflow.float32])\n",
    "        x.set_shape([cls.H,cls.W,3])\n",
    "        y.set_shape([4])\n",
    "        return x,y\n",
    "    \n",
    "    @classmethod \n",
    "    def tensor_dataset(cls,image,b_box,batch=8):\n",
    "        ds = tensorflow.data.Dataset.from_tensor_slices((image,b_box))\n",
    "        ds = ds.map(cls.parse).batch(batch).prefetch(10)\n",
    "        return ds\n",
    "\n",
    "    def run(self):\n",
    "        numpy.random.seed(42)\n",
    "        tensorflow.random.set_seed(42)\n",
    "\n",
    "        batch_size = 16\n",
    "        lr = 1e-4\n",
    "        epochs = 500\n",
    "\n",
    "        (train_x,train_y),(valid_x,valid_y),(test_x,test_y) = self.load_dataset()\n",
    "        training_dataset = self.tensor_dataset(train_x,train_y,batch = batch_size)\n",
    "\n",
    "        validation_dataset = self.tensor_dataset(valid_x,valid_y,batch = batch_size)\n",
    "\n",
    "        model = self.build_model((self.H,self.W,3))\n",
    "\n",
    "        model.compile(\n",
    "            loss = 'binary_crossentropy',\n",
    "            optimizer = Adam(lr)\n",
    "        )\n",
    "\n",
    "        model_path = os.path.join('files','model.h5')\n",
    "        csv_path = os.path.join('files','log.csv')\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(model_path,verbose =1,save_best = True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "            CSVLogger(csv_path, append=True),\n",
    "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "   \n",
    "        ]\n",
    "\n",
    "        history = model.fit(\n",
    "            training_dataset,\n",
    "            epochs = epochs,\n",
    "            validation_data = validation_dataset,\n",
    "            callbacks = callbacks\n",
    "        )\n",
    "        return history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7189\n",
      "Epoch 1: saving model to files/model.h5\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.7189 - val_loss: 0.6756 - lr: 1.0000e-04\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6995\n",
      "Epoch 2: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 940ms/step - loss: 0.6995 - val_loss: 0.6561 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6830\n",
      "Epoch 3: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 953ms/step - loss: 0.6830 - val_loss: 0.6464 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6743\n",
      "Epoch 4: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 930ms/step - loss: 0.6743 - val_loss: 0.6416 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6680\n",
      "Epoch 5: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 932ms/step - loss: 0.6680 - val_loss: 0.6402 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6659\n",
      "Epoch 6: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 858ms/step - loss: 0.6659 - val_loss: 0.6391 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6645\n",
      "Epoch 7: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 873ms/step - loss: 0.6645 - val_loss: 0.6385 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6658\n",
      "Epoch 8: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 926ms/step - loss: 0.6658 - val_loss: 0.6377 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6629\n",
      "Epoch 9: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6629 - val_loss: 0.6364 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6589\n",
      "Epoch 10: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 928ms/step - loss: 0.6589 - val_loss: 0.6352 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6627\n",
      "Epoch 11: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 920ms/step - loss: 0.6627 - val_loss: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6601\n",
      "Epoch 12: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 931ms/step - loss: 0.6601 - val_loss: 0.6338 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6593\n",
      "Epoch 13: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 978ms/step - loss: 0.6593 - val_loss: 0.6332 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6590\n",
      "Epoch 14: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 927ms/step - loss: 0.6590 - val_loss: 0.6329 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6605\n",
      "Epoch 15: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 906ms/step - loss: 0.6605 - val_loss: 0.6330 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6572\n",
      "Epoch 16: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 930ms/step - loss: 0.6572 - val_loss: 0.6331 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6595\n",
      "Epoch 17: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 918ms/step - loss: 0.6595 - val_loss: 0.6328 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6583\n",
      "Epoch 18: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 922ms/step - loss: 0.6583 - val_loss: 0.6328 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6601\n",
      "Epoch 19: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 924ms/step - loss: 0.6601 - val_loss: 0.6328 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6623\n",
      "Epoch 20: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 933ms/step - loss: 0.6623 - val_loss: 0.6325 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6576\n",
      "Epoch 21: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 924ms/step - loss: 0.6576 - val_loss: 0.6323 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6583\n",
      "Epoch 22: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 950ms/step - loss: 0.6583 - val_loss: 0.6322 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6550\n",
      "Epoch 23: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6550 - val_loss: 0.6318 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6588\n",
      "Epoch 24: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 952ms/step - loss: 0.6588 - val_loss: 0.6314 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6552\n",
      "Epoch 25: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 932ms/step - loss: 0.6552 - val_loss: 0.6315 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6579\n",
      "Epoch 26: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.6579 - val_loss: 0.6317 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6550\n",
      "Epoch 27: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 986ms/step - loss: 0.6550 - val_loss: 0.6317 - lr: 1.0000e-04\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6553\n",
      "Epoch 28: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 969ms/step - loss: 0.6553 - val_loss: 0.6314 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6543\n",
      "Epoch 29: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6543 - val_loss: 0.6313 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6550\n",
      "Epoch 30: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 902ms/step - loss: 0.6550 - val_loss: 0.6312 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6554\n",
      "Epoch 31: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 954ms/step - loss: 0.6554 - val_loss: 0.6311 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6544\n",
      "Epoch 32: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 898ms/step - loss: 0.6544 - val_loss: 0.6309 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6540\n",
      "Epoch 33: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 910ms/step - loss: 0.6540 - val_loss: 0.6309 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6522\n",
      "Epoch 34: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 916ms/step - loss: 0.6522 - val_loss: 0.6308 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6528\n",
      "Epoch 35: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 925ms/step - loss: 0.6528 - val_loss: 0.6307 - lr: 1.0000e-04\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6506\n",
      "Epoch 36: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 971ms/step - loss: 0.6506 - val_loss: 0.6307 - lr: 1.0000e-04\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6548\n",
      "Epoch 37: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 925ms/step - loss: 0.6548 - val_loss: 0.6307 - lr: 1.0000e-04\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6533\n",
      "Epoch 38: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 918ms/step - loss: 0.6533 - val_loss: 0.6306 - lr: 1.0000e-04\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6534\n",
      "Epoch 39: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 985ms/step - loss: 0.6534 - val_loss: 0.6304 - lr: 1.0000e-04\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6542\n",
      "Epoch 40: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 946ms/step - loss: 0.6542 - val_loss: 0.6303 - lr: 1.0000e-04\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6527\n",
      "Epoch 41: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 921ms/step - loss: 0.6527 - val_loss: 0.6304 - lr: 1.0000e-04\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6503\n",
      "Epoch 42: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 927ms/step - loss: 0.6503 - val_loss: 0.6304 - lr: 1.0000e-04\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6513\n",
      "Epoch 43: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 922ms/step - loss: 0.6513 - val_loss: 0.6305 - lr: 1.0000e-04\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6520\n",
      "Epoch 44: saving model to files/model.h5\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "8/8 [==============================] - 7s 923ms/step - loss: 0.6520 - val_loss: 0.6305 - lr: 1.0000e-04\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6531\n",
      "Epoch 45: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 936ms/step - loss: 0.6531 - val_loss: 0.6305 - lr: 1.0000e-05\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6515\n",
      "Epoch 46: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 967ms/step - loss: 0.6515 - val_loss: 0.6305 - lr: 1.0000e-05\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6526\n",
      "Epoch 47: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 963ms/step - loss: 0.6526 - val_loss: 0.6305 - lr: 1.0000e-05\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6511\n",
      "Epoch 48: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 974ms/step - loss: 0.6511 - val_loss: 0.6305 - lr: 1.0000e-05\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6518\n",
      "Epoch 49: saving model to files/model.h5\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "8/8 [==============================] - 7s 915ms/step - loss: 0.6518 - val_loss: 0.6305 - lr: 1.0000e-05\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6515\n",
      "Epoch 50: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 939ms/step - loss: 0.6515 - val_loss: 0.6305 - lr: 1.0000e-06\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6517\n",
      "Epoch 51: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 959ms/step - loss: 0.6517 - val_loss: 0.6305 - lr: 1.0000e-06\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6517\n",
      "Epoch 52: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 953ms/step - loss: 0.6517 - val_loss: 0.6305 - lr: 1.0000e-06\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6518\n",
      "Epoch 53: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 928ms/step - loss: 0.6518 - val_loss: 0.6305 - lr: 1.0000e-06\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6519\n",
      "Epoch 54: saving model to files/model.h5\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "8/8 [==============================] - 7s 921ms/step - loss: 0.6519 - val_loss: 0.6305 - lr: 1.0000e-06\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6518\n",
      "Epoch 55: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 936ms/step - loss: 0.6518 - val_loss: 0.6304 - lr: 1.0000e-07\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6513\n",
      "Epoch 56: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 927ms/step - loss: 0.6513 - val_loss: 0.6304 - lr: 1.0000e-07\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6511\n",
      "Epoch 57: saving model to files/model.h5\n",
      "8/8 [==============================] - 7s 916ms/step - loss: 0.6511 - val_loss: 0.6304 - lr: 1.0000e-07\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6512\n",
      "Epoch 58: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 928ms/step - loss: 0.6512 - val_loss: 0.6304 - lr: 1.0000e-07\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6512\n",
      "Epoch 59: saving model to files/model.h5\n",
      "8/8 [==============================] - 8s 947ms/step - loss: 0.6512 - val_loss: 0.6304 - lr: 1.0000e-07\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6532\n",
      "Epoch 60: saving model to files/model.h5\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.6532 - val_loss: 0.6304 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "tracker_obj = Tracker()\n",
    "history = tracker_obj.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

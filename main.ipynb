{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>bbox_x</th>\n",
       "      <th>bbox_y</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gripper</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>298.png</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gripper</td>\n",
       "      <td>99</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>300.png</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gripper</td>\n",
       "      <td>99</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>302.png</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1421</td>\n",
       "      <td>1093</td>\n",
       "      <td>96</td>\n",
       "      <td>406</td>\n",
       "      <td>304.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1425</td>\n",
       "      <td>1078</td>\n",
       "      <td>84</td>\n",
       "      <td>425</td>\n",
       "      <td>306.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1425</td>\n",
       "      <td>1078</td>\n",
       "      <td>84</td>\n",
       "      <td>421</td>\n",
       "      <td>568.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1429</td>\n",
       "      <td>1078</td>\n",
       "      <td>77</td>\n",
       "      <td>421</td>\n",
       "      <td>570.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1429</td>\n",
       "      <td>1074</td>\n",
       "      <td>80</td>\n",
       "      <td>425</td>\n",
       "      <td>572.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1425</td>\n",
       "      <td>1082</td>\n",
       "      <td>84</td>\n",
       "      <td>421</td>\n",
       "      <td>574.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>gripper</td>\n",
       "      <td>1429</td>\n",
       "      <td>1090</td>\n",
       "      <td>80</td>\n",
       "      <td>398</td>\n",
       "      <td>576.png</td>\n",
       "      <td>2880</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_name  bbox_x  bbox_y  bbox_width  bbox_height image_name  \\\n",
       "0      gripper      99      77           5           27    298.png   \n",
       "1      gripper      99      78           5           26    300.png   \n",
       "2      gripper      99      78           5           26    302.png   \n",
       "3      gripper    1421    1093          96          406    304.png   \n",
       "4      gripper    1425    1078          84          425    306.png   \n",
       "..         ...     ...     ...         ...          ...        ...   \n",
       "135    gripper    1425    1078          84          421    568.png   \n",
       "136    gripper    1429    1078          77          421    570.png   \n",
       "137    gripper    1429    1074          80          425    572.png   \n",
       "138    gripper    1425    1082          84          421    574.png   \n",
       "139    gripper    1429    1090          80          398    576.png   \n",
       "\n",
       "     image_width  image_height  \n",
       "0            200           150  \n",
       "1            200           150  \n",
       "2            200           150  \n",
       "3           2880          2160  \n",
       "4           2880          2160  \n",
       "..           ...           ...  \n",
       "135         2880          2160  \n",
       "136         2880          2160  \n",
       "137         2880          2160  \n",
       "138         2880          2160  \n",
       "139         2880          2160  \n",
       "\n",
       "[140 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"inventory annotations.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "    \n",
    "    H = 512\n",
    "    W = 512\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_model(input_shape):\n",
    "        input = layers.Input(input_shape)\n",
    "\n",
    "        pre_trained = MobileNetV2(\n",
    "            include_top = False,\n",
    "            weights = \"imagenet\",\n",
    "            input_tensor = input,\n",
    "            alpha = 1.0\n",
    "        )\n",
    "        pre_trained.trainable = False\n",
    "        x = pre_trained.output\n",
    "        x = layers.Conv2D(256, kernel_size=1, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(4, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(input,x)\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def load_dataset(split = 0.2):\n",
    "        data = pandas.read_csv('/Users/akshitshishodia/tracker/inventory annotations.csv')\n",
    "        path  = '/Users/akshitshishodia/tracker/DATASET_/DATASET_INV/'\n",
    "        image = list()\n",
    "        bounding_box = list()\n",
    "\n",
    "        for idx,rows in data.iterrows():\n",
    "            name = path + str(rows['image_name'])\n",
    "            bbox = [rows['bbox_x'],rows['bbox_y'],rows['bbox_width'],rows['bbox_height']]\n",
    "            image.append(name)\n",
    "            bounding_box.append(bbox)\n",
    "        \n",
    "        sample_size = int(len(image)*0.2)\n",
    "        \n",
    "        train_x, valid_x = train_test_split(image,test_size=sample_size,random_state=42)\n",
    "        train_y, valid_y = train_test_split(bounding_box,test_size=sample_size,random_state=42)\n",
    "\n",
    "        train_x, test_x = train_test_split(train_x,test_size=sample_size,random_state=42)\n",
    "        train_y, test_y = train_test_split(train_y, test_size=sample_size, random_state=42)\n",
    "\n",
    "        return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "    @classmethod\n",
    "    def read_image(cls,path,bbox):\n",
    "        path = path.decode()\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        height,width,_ = img.shape\n",
    "        img = cv2.resize(img,(cls.W,cls.H))\n",
    "        img = (img-127.5)/127.5\n",
    "        img = img.astype(numpy.float32)\n",
    "\n",
    "        x,y,w,h = bbox\n",
    "        x_c = x+w\n",
    "        y_c = y+h\n",
    "\n",
    "        norm_x = float(x/width)\n",
    "        norm_y = float(y/height)\n",
    "        norm_xc = float(x_c/width)\n",
    "        norm_yc = float(y_c/height)\n",
    "        \n",
    "        normalised = numpy.array([norm_x,norm_y,norm_xc,norm_yc],dtype = numpy.float32)\n",
    "\n",
    "        return img, normalised\n",
    "    \n",
    "    @classmethod \n",
    "    def parse(cls,x,y):\n",
    "        x,y = tensorflow.numpy_function(cls.read_image,[x,y],[tensorflow.float32,tensorflow.float32])\n",
    "        x.set_shape([cls.H,cls.W,3])\n",
    "        y.set_shape([4])\n",
    "        return x,y\n",
    "    \n",
    "    @classmethod \n",
    "    def tensor_dataset(cls,image,b_box,batch=8):\n",
    "        ds = tensorflow.data.Dataset.from_tensor_slices((image,b_box))\n",
    "        ds = ds.map(cls.parse).batch(batch).prefetch(10)\n",
    "        return ds\n",
    "\n",
    "    def run(self):\n",
    "        numpy.random.seed(42)\n",
    "        tensorflow.random.set_seed(42)\n",
    "\n",
    "        batch_size = 16\n",
    "        lr = 1e-4\n",
    "        epochs = 500\n",
    "\n",
    "        (train_x,train_y),(valid_x,valid_y),(test_x,test_y) = self.load_dataset()\n",
    "        training_dataset = self.tensor_dataset(train_x,train_y,batch = batch_size)\n",
    "\n",
    "        validation_dataset = self.tensor_dataset(valid_x,valid_y,batch = batch_size)\n",
    "\n",
    "        model = self.build_model((self.H,self.W,3))\n",
    "\n",
    "        model.compile(\n",
    "            loss = 'binary_crossentropy',\n",
    "            optimizer = Adam(lr)\n",
    "        )\n",
    "\n",
    "        model_path = os.path.join('files','model_3.h5')\n",
    "        csv_path = os.path.join('files','log_3.csv')\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(model_path,verbose =1,save_best = True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "            CSVLogger(csv_path, append=True),\n",
    "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "   \n",
    "        ]\n",
    "\n",
    "        history = model.fit(\n",
    "            training_dataset,\n",
    "            epochs = epochs,\n",
    "            validation_data = validation_dataset,\n",
    "            callbacks = callbacks\n",
    "        )\n",
    "        return history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:2@146.155] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV538.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.523179: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:3@146.156] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV484.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.525685: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:2@146.158] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV354.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.525862: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:3@146.158] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV526.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.526007: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:3@146.158] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV344.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.526115: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:3@146.158] global loadsave.cpp:244 findDecoder imread_('/Users/akshitshishodia/tracker/DATASET_/DATASET_INV378.png'): can't open/read file: check file path/integrity\n",
      "2023-07-19 13:08:30.526247: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n",
      "    height,width,_ = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nAttributeError: 'NoneType' object has no attribute 'shape'\nTraceback (most recent call last):\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n    height,width,_ = img.shape\n\nAttributeError: 'NoneType' object has no attribute 'shape'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_15761]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tracker_obj \u001b[39m=\u001b[39m Tracker()\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m tracker_obj\u001b[39m.\u001b[39;49mrun()\n",
      "Cell \u001b[0;32mIn[14], line 120\u001b[0m, in \u001b[0;36mTracker.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlog_3.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m    113\u001b[0m     ModelCheckpoint(model_path,verbose \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,save_best \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    114\u001b[0m     ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m ]\n\u001b[0;32m--> 120\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    121\u001b[0m     training_dataset,\n\u001b[1;32m    122\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    123\u001b[0m     validation_data \u001b[39m=\u001b[39;49m validation_dataset,\n\u001b[1;32m    124\u001b[0m     callbacks \u001b[39m=\u001b[39;49m callbacks\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nAttributeError: 'NoneType' object has no attribute 'shape'\nTraceback (most recent call last):\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_93796/658823430.py\", line 58, in read_image\n    height,width,_ = img.shape\n\nAttributeError: 'NoneType' object has no attribute 'shape'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_15761]"
     ]
    }
   ],
   "source": [
    "tracker_obj = Tracker()\n",
    "history = tracker_obj.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

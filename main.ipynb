{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_name</th>\n",
       "      <th>bbox_x</th>\n",
       "      <th>bbox_y</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>574</td>\n",
       "      <td>498</td>\n",
       "      <td>102</td>\n",
       "      <td>130</td>\n",
       "      <td>frame0.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>539</td>\n",
       "      <td>498</td>\n",
       "      <td>97</td>\n",
       "      <td>130</td>\n",
       "      <td>frame10.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>350</td>\n",
       "      <td>590</td>\n",
       "      <td>74</td>\n",
       "      <td>120</td>\n",
       "      <td>frame100.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>347</td>\n",
       "      <td>597</td>\n",
       "      <td>77</td>\n",
       "      <td>120</td>\n",
       "      <td>frame105.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>345</td>\n",
       "      <td>585</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>frame110.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>585</td>\n",
       "      <td>643</td>\n",
       "      <td>77</td>\n",
       "      <td>128</td>\n",
       "      <td>frame725.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>388</td>\n",
       "      <td>615</td>\n",
       "      <td>92</td>\n",
       "      <td>123</td>\n",
       "      <td>frame80.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>368</td>\n",
       "      <td>613</td>\n",
       "      <td>107</td>\n",
       "      <td>123</td>\n",
       "      <td>frame85.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>370</td>\n",
       "      <td>600</td>\n",
       "      <td>77</td>\n",
       "      <td>133</td>\n",
       "      <td>frame90.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Gripper</td>\n",
       "      <td>355</td>\n",
       "      <td>592</td>\n",
       "      <td>82</td>\n",
       "      <td>133</td>\n",
       "      <td>frame95.jpg</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_name  bbox_x  bbox_y  ...    image_name  image_width image_height\n",
       "0      Gripper     574     498  ...    frame0.jpg         1920         1080\n",
       "1      Gripper     539     498  ...   frame10.jpg         1920         1080\n",
       "2      Gripper     350     590  ...  frame100.jpg         1920         1080\n",
       "3      Gripper     347     597  ...  frame105.jpg         1920         1080\n",
       "4      Gripper     345     585  ...  frame110.jpg         1920         1080\n",
       "..         ...     ...     ...  ...           ...          ...          ...\n",
       "139    Gripper     585     643  ...  frame725.jpg         1920         1080\n",
       "140    Gripper     388     615  ...   frame80.jpg         1920         1080\n",
       "141    Gripper     368     613  ...   frame85.jpg         1920         1080\n",
       "142    Gripper     370     600  ...   frame90.jpg         1920         1080\n",
       "143    Gripper     355     592  ...   frame95.jpg         1920         1080\n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pandas.read_csv(\"/Users/akshitshishodia/intern/labels_my-project-name_2023-06-27-09-45-54.csv\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker():\n",
    "    \n",
    "    H = 512\n",
    "    W = 512\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_model(input_shape):\n",
    "        input = layers.Input(input_shape)\n",
    "\n",
    "        pre_trained = MobileNetV2(\n",
    "            include_top = False,\n",
    "            weights = \"imagenet\",\n",
    "            input_tensor = input,\n",
    "            alpha = 1.0\n",
    "        )\n",
    "        pre_trained.trainable = False\n",
    "        x = pre_trained.output\n",
    "        x = layers.Conv2D(256, kernel_size=1, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(4, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(input,x)\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def load_dataset(split = 0.2):\n",
    "        data = pandas.read_csv('labels_my-project-name_2023-06-27-09-45-54.csv')\n",
    "        path  = 'dataset'\n",
    "        image = list()\n",
    "        bounding_box = list()\n",
    "\n",
    "        for idx,rows in data.iterrows():\n",
    "            name = path + str(rows['image_name'])\n",
    "            bbox = [rows['bbox_x'],rows['bbox_y'],rows['bbox_width'],rows['bbox_height']]\n",
    "            image.append(name)\n",
    "            bounding_box.append(bbox)\n",
    "        \n",
    "        sample_size = int(len(image)*0.2)\n",
    "        \n",
    "        train_x, valid_x = train_test_split(image,test_size=sample_size,random_state=42)\n",
    "        train_y, valid_y = train_test_split(bounding_box,test_size=sample_size,random_state=42)\n",
    "\n",
    "        train_x, test_x = train_test_split(train_x,test_size=sample_size,random_state=42)\n",
    "        train_y, test_y = train_test_split(train_y, test_size=sample_size, random_state=42)\n",
    "\n",
    "        return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "    @classmethod\n",
    "    def read_image(cls,path,bbox):\n",
    "        \n",
    "        img = cv2.imread('dataset'+str(path),cv2.IMREAD_COLOR)\n",
    "        height,width = img.shape\n",
    "        img = cv2.reshape(img,(cls.W,cls.H))\n",
    "        img = (img-127.5)/127.5\n",
    "        img = img.astype(numpy.float32)\n",
    "\n",
    "        x,y,w,h = bbox\n",
    "        x_c = x+w\n",
    "        y_c = y+h\n",
    "\n",
    "        norm_x = float(x/width)\n",
    "        norm_y = float(y/height)\n",
    "        norm_xc = float(x_c/width)\n",
    "        norm_yc = float(y_c/height)\n",
    "        \n",
    "        normalised = numpy.array([norm_x,norm_y,norm_xc,norm_yc])\n",
    "\n",
    "        return img, normalised\n",
    "    \n",
    "    @classmethod \n",
    "    def parse(cls,x,y):\n",
    "        x,y = tensorflow.numpy_function(cls.read_image,[x,y],[tensorflow.float32,tensorflow.float32])\n",
    "        x.set_shape([cls.H,cls.W,3])\n",
    "        y.set_shape([4])\n",
    "        return x,y\n",
    "    \n",
    "    @classmethod \n",
    "    def tensor_dataset(cls,image,b_box,batch=8):\n",
    "        ds = tensorflow.data.Dataset.from_tensor_slices((image,b_box))\n",
    "        ds = ds.map(cls.parse).batch(batch).prefetch(10)\n",
    "        return ds\n",
    "\n",
    "    def run(self):\n",
    "        numpy.random.seed(42)\n",
    "        tensorflow.random.set_seed(42)\n",
    "\n",
    "        batch_size = 16\n",
    "        lr = 1e-4\n",
    "        epochs = 500\n",
    "\n",
    "        (train_x,train_y),(valid_x,valid_y),(test_x,test_y) = self.load_dataset()\n",
    "        training_dataset = self.tensor_dataset(train_x,train_y,batch = batch_size)\n",
    "\n",
    "        validation_dataset = self.tensor_dataset(valid_x,valid_y,batch = batch_size)\n",
    "\n",
    "        model = self.build_model((self.H,self.W,3))\n",
    "\n",
    "        model.compile(\n",
    "            loss = 'binary_crossentropy',\n",
    "            optimizer = Adam(lr)\n",
    "        )\n",
    "\n",
    "        model_path = os.path.join('files','model.h5')\n",
    "        csv_path = os.path.join('files','log.csv')\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(model_path,verbose =1,save_best = True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "            CSVLogger(csv_path, append=True),\n",
    "            EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "   \n",
    "        ]\n",
    "\n",
    "        model.fit(\n",
    "            training_dataset,\n",
    "            epochs = epochs,\n",
    "            validation_data = validation_dataset,\n",
    "            callbacks = callbacks\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:2@3660.226] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe50.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.605833: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:3@3660.228] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe270.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.608399: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:2@3660.228] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe60.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.608554: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:2@3660.229] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe590.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.608658: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:2@3660.229] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe265.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.608831: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n",
      "[ WARN:2@3660.229] global loadsave.cpp:244 findDecoder imread_('datasetb'datasetframe210.jpg''): can't open/read file: check file path/integrity\n",
      "2023-07-03 15:07:14.609010: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n",
      "    height,width = img.shape\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nAttributeError: 'NoneType' object has no attribute 'shape'\nTraceback (most recent call last):\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n    height,width = img.shape\n\nAttributeError: 'NoneType' object has no attribute 'shape'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_15808]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tracker_obj \u001b[39m=\u001b[39m Tracker()\n\u001b[0;32m----> 2\u001b[0m tracker_obj\u001b[39m.\u001b[39;49mrun()\n",
      "Cell \u001b[0;32mIn[32], line 120\u001b[0m, in \u001b[0;36mTracker.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlog.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m    113\u001b[0m     ModelCheckpoint(model_path,verbose \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,save_best \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    114\u001b[0m     ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m ]\n\u001b[0;32m--> 120\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    121\u001b[0m     training_dataset,\n\u001b[1;32m    122\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    123\u001b[0m     validation_data \u001b[39m=\u001b[39;49m validation_dataset,\n\u001b[1;32m    124\u001b[0m     callbacks \u001b[39m=\u001b[39;49m callbacks\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nAttributeError: 'NoneType' object has no attribute 'shape'\nTraceback (most recent call last):\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/akshitshishodia/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/zy/_wdf8zn51qq_j543bvqj82x40000gn/T/ipykernel_99543/301141794.py\", line 58, in read_image\n    height,width = img.shape\n\nAttributeError: 'NoneType' object has no attribute 'shape'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_15808]"
     ]
    }
   ],
   "source": [
    "tracker_obj = Tracker()\n",
    "tracker_obj.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "H = 512\n",
    "W = 512\n",
    "    \n",
    "def build_model(input_shape):\n",
    "    input = layers.Input(input_shape)\n",
    "\n",
    "    pre_trained = MobileNetV2(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_tensor = input,\n",
    "        alpha = 1.0\n",
    "    )\n",
    "    pre_trained.trainable = False\n",
    "    x = pre_trained.output\n",
    "    x = layers.Conv2D(256, kernel_size=1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(4, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(input,x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_dataset(split = 0.2):\n",
    "    data = pandas.read_csv('labels_my-project-name_2023-06-27-09-45-54.csv')\n",
    "    path  = '/Users/akshitshishodia/intern/tracker/dataset/'\n",
    "    image = list()\n",
    "    bounding_box = list()\n",
    "\n",
    "    for idx,rows in data.iterrows():\n",
    "        name = path + str(rows['image_name'])\n",
    "        bbox = [rows['bbox_x'],rows['bbox_y'],rows['bbox_width'],rows['bbox_height']]\n",
    "        image.append(name)\n",
    "        bounding_box.append(bbox)\n",
    "    \n",
    "    sample_size = int(len(image)*0.2)\n",
    "    \n",
    "    train_x, valid_x = train_test_split(image,test_size=sample_size,random_state=42)\n",
    "    train_y, valid_y = train_test_split(bounding_box,test_size=sample_size,random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x,test_size=sample_size,random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=sample_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path,bbox):\n",
    "    path = path.decode()\n",
    "    img = cv2.imread(path)\n",
    "    height,width,_ = img.shape\n",
    "    img = cv2.resize(img,(W,H))\n",
    "    img = (img-127.5)/127.5\n",
    "\n",
    "    img = img.astype(numpy.float32)\n",
    "\n",
    "    x,y,w,h = bbox\n",
    "    x_c = x+w\n",
    "    y_c = y+h\n",
    "\n",
    "    norm_x = float(x/width)\n",
    "    norm_y = float(y/height)\n",
    "    norm_xc = float(x_c/width)\n",
    "    norm_yc = float(y_c/height)\n",
    "    \n",
    "    normalised = numpy.array([norm_x,norm_y,norm_xc,norm_yc],dtype = numpy.float32)\n",
    "\n",
    "\n",
    "    return img, normalised\n",
    "\n",
    "def parse(x,y):\n",
    "    x,y = tensorflow.numpy_function(read_image,[x,y],[tensorflow.float32,tensorflow.float32])\n",
    "    x.set_shape([H,W,3])\n",
    "    y.set_shape([4])\n",
    "    return x,y\n",
    "\n",
    "def tensor_dataset(image,b_box,batch=8):\n",
    "    ds = tensorflow.data.Dataset.from_tensor_slices((image,b_box))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(10)\n",
    "    return ds\n",
    "\n",
    "def run():\n",
    "    numpy.random.seed(42)\n",
    "    tensorflow.random.set_seed(42)\n",
    "\n",
    "    batch_size = 16\n",
    "    lr = 1e-4\n",
    "    epochs = 500\n",
    "\n",
    "    (train_x,train_y),(valid_x,valid_y),(test_x,test_y) = load_dataset()\n",
    "    training_dataset = tensor_dataset(train_x,train_y,batch = batch_size)\n",
    "\n",
    "    validation_dataset = tensor_dataset(valid_x,valid_y,batch = batch_size)\n",
    "\n",
    "    model = build_model((H,W,3))\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = Adam(lr)\n",
    "    )\n",
    "\n",
    "    model_path = os.path.join('files','model.h5')\n",
    "    csv_path = os.path.join('files','log.csv')\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path,verbose =1,save_best = True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        training_dataset,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks = callbacks\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x,train_y),(valid_x,valid_y),(test_x,test_y) = load_dataset()\n",
    "training_dataset = tensor_dataset(train_x,train_y,batch = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n1-th value returned by pyfunc_39 is double, but expects float\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_114003]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run()\n",
      "Cell \u001b[0;32mIn[95], line 111\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m csv_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlog.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    103\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     ModelCheckpoint(model_path,verbose \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,save_best \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    105\u001b[0m     ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m ]\n\u001b[0;32m--> 111\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    112\u001b[0m     training_dataset,\n\u001b[1;32m    113\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs,\n\u001b[1;32m    114\u001b[0m     validation_data \u001b[39m=\u001b[39;49m validation_dataset,\n\u001b[1;32m    115\u001b[0m     callbacks \u001b[39m=\u001b[39;49m callbacks\n\u001b[1;32m    116\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n1-th value returned by pyfunc_39 is double, but expects float\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_114003]"
     ]
    }
   ],
   "source": [
    "run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
